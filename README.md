# Convolution-Neural-Network
Developed a system to interpret the American Sign Language signs into corresponding English Letters. 

In this project, Used the dataset prepared by Nicolas Pugeault and Richard Bowden from their Center for Vision, Speech and Signal Processing lab at University of Surrey, UK. 
Downloaded the dataset from http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset. This dataset compresed of 24 signs excluding the letters J and Z becuase they involve motion and can't be represented as an image. The image dataset was split into train and test dataset. Implemented the CNN classifer and tested the test dataset. Also in this project developed a program to take a video recording (30 frames per sec) from webcame to record a sequence of signs played from user and developed the classifier. 
